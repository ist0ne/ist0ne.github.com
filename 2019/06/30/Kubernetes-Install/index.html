<!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>高可用 Kubernetes 集群部署 | 石头记 | Docker、Kubernetes、CI/CD 等技术分享</title>

  
  <meta name="author" content="ist0ne">
  

  
  <meta name="description" content="Docker、Kubernetes、Ceph、Saltstack、OpenStack 等技术分享">
  

  
  <meta name="keywords" content="blog kubernetes k8s docker container ceph salt saltstack openstack kube kubectl helm charts gitlab git">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <meta property="og:title" content="高可用 Kubernetes 集群部署">

  <meta property="og:site_name" content="石头记">

  
  <meta property="og:image" content="/favicon.ico">
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="石头记" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
</head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">石头记</a>
    </h1>
    <p class="site-description">Docker、Kubernetes、CI/CD 等技术分享</p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">主页</a></li>
      
        <li><a href="/archives">归档</a></li>
      
        <li><a href="/atom.xml">订阅</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    <article>

  
    
    <h3 class="article-title"><span>高可用 Kubernetes 集群部署</span></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2019/06/30/Kubernetes-Install/" rel="bookmark">
        <time class="entry-date published" datetime="2019-06-30T04:09:18.000Z">
          2019-06-30
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <blockquote>
<p><strong>视频课程地址：</strong><a href="https://www.bilibili.com/video/av49387629?from=search&seid=4418298671230182069" target="_blank" rel="noopener">戳我开始学习</a></p>
</blockquote>
<h2 id="Kubernetes版本选择"><a href="#Kubernetes版本选择" class="headerlink" title="Kubernetes版本选择"></a>Kubernetes版本选择</h2><p>Kubernetes 1.14是2019年发布的第一个正式版本。新版本有31个增强功能：其中有10个功能进入了生产可用状态，12个进入了beta版本，另外，增加了7个新功能。1.14版本的主题是可扩展性，支持更多Kubernetes工作负载，其中三个主要功能正式推出，以及一个重要的安全功能转向beta。与之前发布的Kubernetes版本相比，1.14版本中的更多功能逐渐稳定，这是大家期望的重要里程碑。</p>
<ul>
<li><strong>生产级别的Windwos节点支持</strong> Kubernetes1.14版本正式支持将Windows节点添加为工作节点，这意味着可以在生产环境使用Windows容器了，使庞大的Windows应用生态系统能够利用Kubernetes平台的强大功能了。</li>
<li><strong>Kubectl的更新</strong> 新版本Kubectl可以使用声明性Resource Config来管理资源。kubectl的文档也从头进行编写，可参考<a href="https://kubectl.docs.kubernetes.io" target="_blank" rel="noopener">文档</a>。</li>
<li><strong>持久化本地Volumes</strong> 本地SSD比远程磁盘能提供更好的性能。对性能要求比较高的数据库和分布式文件系统可以使用久化本地存储。</li>
</ul>
<h2 id="准备节点"><a href="#准备节点" class="headerlink" title="准备节点"></a>准备节点</h2><p>通过kubeadm部署高可用Kubernetes集群有两种架构，一种是将数据平面（etcd集群）和控制平面（Kubernetes控制节点）部署在一起，另一种是分开部署，其中部署在一起可以节省服务器，但是数据平面和控制平面耦合在一起，当一台机器故障时，数据平面和控制平面将同时出现问题。</p>
<p>数据平面和控制平面共用节点：</p>
<p><img src="imgs/201907/kubeadm-ha-topology-stacked-etcd.png" alt="数据平面和控制平面共用节点"></p>
<p>数据平面和控制平面不共用节点：</p>
<p><img src="imgs/201907/kubeadm-ha-topology-external-etcd.png" alt="数据平面和控制平面不共用节点"></p>
<p>我们按照数据平面和控制平面共用节点进行高可用集群的部署。</p>
<h2 id="升级各节点系统"><a href="#升级各节点系统" class="headerlink" title="升级各节点系统"></a>升级各节点系统</h2><p>操作系统我们选择 CentOS 7 最新版（7.6.1810），如果不是最新版，可参考如下升级到最新版。</p>
<p>按如下内容，编辑 /etc/yum.repos.d/CentOS-Base.repo</p>
<pre><code># CentOS-Base.repo
#
# The mirror system uses the connecting IP address of the client and the
# update status of each mirror to pick mirrors that are updated to and
# geographically close to the client.  You should use this for CentOS updates
# unless you are manually picking other mirrors.
#
# If the mirrorlist= does not work for you, as a fall back you can try the
# remarked out baseurl= line instead.
#
#

[base]
name=CentOS-$releasever - Base
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=os&amp;infra=$infra
baseurl=http://mirrors.163.com/centos/7.6.1810/os/$basearch/
#baseurl=http://mirror.centos.org/centos/$releasever/os/$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7

#released updates
[updates]
name=CentOS-$releasever - Updates
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updates&amp;infra=$infra
baseurl=http://mirrors.163.com/centos/7.6.1810/updates/$basearch/
#baseurl=http://mirror.centos.org/centos/$releasever/updates/$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7

#additional packages that may be useful
[extras]
name=CentOS-$releasever - Extras
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extras&amp;infra=$infra
baseurl=http://mirrors.163.com/centos/7.6.1810/extras/$basearch/
#baseurl=http://mirror.centos.org/centos/$releasever/extras/$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7

#additional packages that extend functionality of existing packages
[centosplus]
name=CentOS-$releasever - Plus
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=centosplus&amp;infra=$infra
baseurl=http://mirrors.163.com/centos/7.6.1810/centosplus/$basearch/
#baseurl=http://mirror.centos.org/centos/$releasever/centosplus/$basearch/
gpgcheck=1
enabled=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7</code></pre><p>升级系统并重启</p>
<pre><code>$ yum update -y
$ reboot</code></pre><p>关闭SELinux，编辑 /etc/sysconfig/selinux，设置SELINUX=disabled</p>
<pre><code>$ setenforce 0</code></pre><p>配置内核参数</p>
<pre><code>$ cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
vm.swappiness = 0
EOF
$ sysctl --system</code></pre><p>Kubernetes v1.8+ 要求关闭系统 Swap，请在所有节点利用以下指令关闭：</p>
<pre><code>$ swapoff -a &amp;&amp; sysctl -w vm.swappiness=0

$ vi /etc/fstab
注释swap相关的行</code></pre><p>设置各节点主机名：</p>
<pre><code>hostnamectl set-hostname k8s-m1
hostnamectl set-hostname k8s-m2
hostnamectl set-hostname k8s-m3
hostnamectl set-hostname k8s-s1
hostnamectl set-hostname k8s-s2</code></pre><p>修改hosts，添加如下行：</p>
<pre><code>172.16.10.48 k8s-m001
172.16.10.49 k8s-m002
172.16.10.50 k8s-m003
172.16.10.51 k8s-s001
172.16.10.52 k8s-s002
172.16.10.53 k8s-s002</code></pre><h2 id="配置所有节点加载ipvs相关模块（kube-proxy-使用ipvs模式）"><a href="#配置所有节点加载ipvs相关模块（kube-proxy-使用ipvs模式）" class="headerlink" title="配置所有节点加载ipvs相关模块（kube-proxy 使用ipvs模式）"></a>配置所有节点加载ipvs相关模块（kube-proxy 使用ipvs模式）</h2><p>加载相关内核模块</p>
<pre><code>$ cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt; EOF
#!/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack_ipv4
EOF

$ chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4</code></pre><p>安装相关软件包</p>
<pre><code>$ yum install -y ipset ipvsadm</code></pre><h2 id="配置ssh-key认证"><a href="#配置ssh-key认证" class="headerlink" title="配置ssh key认证"></a>配置ssh key认证</h2><p>在主节点1上执行生成公钥</p>
<pre><code>$ ssh-keygen</code></pre><p>拷贝 /root/.ssh/id_rsa.pub 内容到主节点2和主节点3上</p>
<pre><code>$ vi /home/centos/.ssh/authorized_keys</code></pre><h2 id="所有节点安装-Docker"><a href="#所有节点安装-Docker" class="headerlink" title="所有节点安装 Docker"></a>所有节点安装 Docker</h2><p>推荐安装 1.13.1, 17.03, 17.06, 17.09, 18.06, 18.09，但是18.09+是未经测试的，不推荐使用。</p>
<p>安装依赖包</p>
<pre><code>$ yum install -y yum-utils \
device-mapper-persistent-data \
lvm2</code></pre><p>添加docker yum仓库</p>
<pre><code>$  yum-config-manager \
--add-repo \
https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</code></pre><p>安装 Docker</p>
<pre><code>yum install -y docker-ce docker-ce-cli containerd.io</code></pre><p>配置 Docker</p>
<pre><code>$ cat &lt;&lt; EOF &gt; /etc/docker/daemon.json
{
&quot;insecure-registry&quot;: [
    &quot;hub.hipstershop.cn&quot;,
    &quot;reg.hipstershop.cn&quot;
],
&quot;registry-mirror&quot;: &quot;https://q00c7e05.mirror.aliyuncs.com&quot;,
&quot;graph&quot;: &quot;/data1/docker&quot;
}
EOF</code></pre><p>启动Docker</p>
<pre><code>systemctl enable docker &amp;&amp; systemctl start docker</code></pre><h2 id="所有节点安装kubeadm-kubelet-and-kubectl"><a href="#所有节点安装kubeadm-kubelet-and-kubectl" class="headerlink" title="所有节点安装kubeadm, kubelet and kubectl"></a>所有节点安装kubeadm, kubelet and kubectl</h2><p>kubelet版本要与待安装的Kubernetes版本相同，否则可能会出现一些难以预料的问题。</p>
<pre><code>$ cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
       http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF</code></pre><p>通过 yum 安装软件包</p>
<pre><code>yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes</code></pre><p>设置开机自动启动kubelet</p>
<pre><code>systemctl enable kubelet.service</code></pre><h2 id="使用kubeadm创建高可用集群（数据平面和控制平面放置到一起）"><a href="#使用kubeadm创建高可用集群（数据平面和控制平面放置到一起）" class="headerlink" title="使用kubeadm创建高可用集群（数据平面和控制平面放置到一起）"></a>使用kubeadm创建高可用集群（数据平面和控制平面放置到一起）</h2><h3 id="创建第一个节点控制节点"><a href="#创建第一个节点控制节点" class="headerlink" title="创建第一个节点控制节点"></a>创建第一个节点控制节点</h3><p>创建配置文件 kubeadm-config.yaml：</p>
<pre><code>apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
mode: &quot;ipvs&quot;
---
apiVersion: kubeadm.k8s.io/v1beta1
kind: ClusterConfiguration
kubernetesVersion: v1.14.3
apiServer:
    certSANs:
    - &quot;apiserver.hipstershop.cn&quot;
    - &quot;172.16.1.50&quot;
    - &quot;172.16.10.48&quot;
    - &quot;172.16.10.49&quot;
    - &quot;172.16.10.50&quot;
    extraArgs:
        allow-privileged: &quot;true&quot;
        feature-gates: &quot;VolumeSnapshotDataSource=true,CSINodeInfo=true,    CSIDriverRegistry=true&quot;
controlPlaneEndpoint: &quot;apiserver.hipstershop.cn:6443&quot;
etcd:
    local:
        dataDir: /data1/etcd
networking:
    # This CIDR is a Canal default. Substitute or remove for your CNI     provider.
    podSubnet: &quot;10.244.0.0/16&quot;
controllerManager:
    extraArgs:
        address: 0.0.0.0
scheduler:
    extraArgs:
        address: 0.0.0.0
imageRepository: gcr.azk8s.cn/google-containers</code></pre><blockquote>
<p>172.16.1.50 为APIServer的负载均衡IP，6443为负载均衡的端口。如果没有负载均可以通过 HaProxy自行搭建，参见<a href="https://github.com/findsec-cn/k200/raw/master/1.高可用性集群部署/kHaProxy负载均衡配置.md" target="_blank" rel="noopener">HaProxy负载均衡配置</a>。如果公司有硬件负载均衡如f5、Netscaler等可以直接使用；如果在各云平台可以使用各云平台的负载均衡（如阿里云的SLB）。<br>如果你不能直接访问gcr.io，需要设置imageRepository: gcr.azk8s.cn/google-containers。</p>
</blockquote>
<h3 id="初始化第一个节点"><a href="#初始化第一个节点" class="headerlink" title="初始化第一个节点"></a>初始化第一个节点</h3><pre><code>kubeadm init --config=kubeadm-config.yaml
......
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:
https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of machines by running the following on each node
as root:

kubeadm join apiserver.hipstershop.com:6443 --token skvqhu.b297uimw0omi26w0 --discovery-token-ca-cert-hash sha256:b3b23ae7aea87baa02eda31f7fdbd2604e4cfa20a9f9c278671816d630f30d22</code></pre><blockquote>
<p>注意：以上(kubeadm join)输出在其他节点加入时会使用，需要妥善保管</p>
</blockquote>
<h3 id="配置网络节点"><a href="#配置网络节点" class="headerlink" title="配置网络节点"></a>配置网络节点</h3><p>在此选择Canal网络组件，其他网络组建见：<a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a></p>
<pre><code>$ mkdir -p $HOME/.kube
$ cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
$ chown $(id -u):$(id -g) $HOME/.kube/config

$ kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/canal/rbac.yaml
$ kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/canal/canal.yaml</code></pre><p>等待第一个节点 pod 都变为运行状态</p>
<pre><code>kubectl get pod -n kube-system
NAME                                       READY   STATUS    RESTARTS   AGE
canal-xp9tm                                3/3     Running   0          79s
coredns-86c58d9df4-d62mw                   1/1     Running   0          2m37s
coredns-86c58d9df4-wq26g                   1/1     Running   0          2m37s
etcd-k8s-m1.novalocal                      1/1     Running   0          2m3s
kube-apiserver-k8s-m1.novalocal            1/1     Running   0          115s
kube-controller-manager-k8s-m1.novalocal   1/1     Running   0          2m21s
kube-proxy-t8x22                           1/1     Running   0          2m37s
kube-scheduler-k8s-m1.novalocal            1/1     Running   0          2m12s</code></pre><h3 id="复制证书到其他控制节点"><a href="#复制证书到其他控制节点" class="headerlink" title="复制证书到其他控制节点"></a>复制证书到其他控制节点</h3><pre><code>USER=centos
CONTROL_PLANE_IPS=&quot;172.16.10.49 172.16.10.50&quot;
for host in ${CONTROL_PLANE_IPS}; do
    scp /etc/kubernetes/pki/ca.crt &quot;${USER}&quot;@$host:
    scp /etc/kubernetes/pki/ca.key &quot;${USER}&quot;@$host:
    scp /etc/kubernetes/pki/sa.key &quot;${USER}&quot;@$host:
    scp /etc/kubernetes/pki/sa.pub &quot;${USER}&quot;@$host:
    scp /etc/kubernetes/pki/front-proxy-ca.crt &quot;${USER}&quot;@$host:
    scp /etc/kubernetes/pki/front-proxy-ca.key &quot;${USER}&quot;@$host:
    scp /etc/kubernetes/pki/etcd/ca.crt &quot;${USER}&quot;@$host:etcd-ca.crt
    scp /etc/kubernetes/pki/etcd/ca.key &quot;${USER}&quot;@$host:etcd-ca.key
    scp /etc/kubernetes/admin.conf &quot;${USER}&quot;@$host:
done</code></pre><h3 id="登录第二、三个控制节点移动证书到正确位置"><a href="#登录第二、三个控制节点移动证书到正确位置" class="headerlink" title="登录第二、三个控制节点移动证书到正确位置"></a>登录第二、三个控制节点移动证书到正确位置</h3><pre><code>USER=centos
mkdir -p /etc/kubernetes/pki/etcd
mv /home/${USER}/ca.crt /etc/kubernetes/pki/
mv /home/${USER}/ca.key /etc/kubernetes/pki/
mv /home/${USER}/sa.pub /etc/kubernetes/pki/
mv /home/${USER}/sa.key /etc/kubernetes/pki/
mv /home/${USER}/front-proxy-ca.crt /etc/kubernetes/pki/
mv /home/${USER}/front-proxy-ca.key /etc/kubernetes/pki/
mv /home/${USER}/etcd-ca.crt /etc/kubernetes/pki/etcd/ca.crt
mv /home/${USER}/etcd-ca.key /etc/kubernetes/pki/etcd/ca.key
mv /home/${USER}/admin.conf /etc/kubernetes/admin.conf</code></pre><h3 id="将第二、三个控制节点加入集群"><a href="#将第二、三个控制节点加入集群" class="headerlink" title="将第二、三个控制节点加入集群"></a>将第二、三个控制节点加入集群</h3><blockquote>
<p>注意：加入集群的命令请使用第一个节点安装完成后生生成的命令。</p>
</blockquote>
<pre><code># 在第二个控制节点执行
$ kubeadm join apiserver.hipstershop.cn:6443 --token skvqhu.b297uimw0omi26w0 --discovery-token-ca-cert-hash sha256:b3b23ae7aea87baa02eda31f7fdbd2604e4cfa20a9f9c278671816d630f30d22 --experimental-control-plane
# 在第三个控制节点执行
$ kubeadm join apiserver.hipstershop.cn:6443 --token skvqhu.b297uimw0omi26w0 --discovery-token-ca-cert-hash sha256:b3b23ae7aea87baa02eda31f7fdbd2604e4cfa20a9f9c278671816d630f30d22 --experimental-control-plane</code></pre><h3 id="将从节点加入集群"><a href="#将从节点加入集群" class="headerlink" title="将从节点加入集群"></a>将从节点加入集群</h3><blockquote>
<p>注意：加入集群的命令请使用第一个节点安装完成后生生成的命令。</p>
</blockquote>
<pre><code># 在s1,s2,s3节点执行
$ kubeadm join apiserver.hipstershop.cn:6443 --token skvqhu.b297uimw0omi26w0 --discovery-token-ca-cert-hash sha256:b3b23ae7aea87baa02eda31f7fdbd2604e4cfa20a9f9c278671816d630f30d22</code></pre>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/docker/">docker</a><a href="/tags/container/">container</a><a href="/tags/kubernetes/">kubernetes</a><a href="/tags/k8s/">k8s</a><a href="/tags/kubeadm/">kubeadm</a><a href="/tags/kubectl/">kubectl</a><a href="/tags/helm/">helm</a>
    </span>
    

    </div>

    
  </div>
</article>

  

	<section id="comment" class="comment">
		<div id="gitment"></div>
	</section>
	<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
	<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
	<script>
		var gitment = new Gitment({
			owner: 'ist0ne',
			repo: 'gitment',
			oauth: {
				client_id: 'a3a5af94aef00fdf0c24',
				client_secret: '3d47316b6b7d0b98ba405da19a65457357256f2d',
			},
		})
		gitment.render('gitment')
	</script>





    </main>

    <footer class="site-footer">
  <p class="site-info">
    Proudly powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    </br>
    
    &copy; 2019 ist0ne
    
  </p>
</footer>
    
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-39923501-1', 'auto');
    ga('send', 'pageview');

</script>

  </div>
</div>
</body>
</html>